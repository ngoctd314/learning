# Data type

## Creating confusion with octal literals

Go handles binary, hexadecimal, imaginary, and octal numbers. Octal numbers start wiht a 0. However, to improve readability and avoid potential mistakes for future code readers, make octal numbers explicit using 0o prefix.

## Neglecting integer overflows

Not understanding how integer overflows are handled in Go can lead to critical bugs.

### Concepts

### Detecting integer overflow when incrementing

If we want to detect an integer overflow during an increment operation with a type based on a defined size (int8, int16, int32, int64, uint8, uint16, or uint64)

```go
func Inc32(counter int32) int32 {
    if counter == math.MaxInt32 {
        panic("int32 overflow")
    }
    return coutner + 1
}
```

### Detecting integer overflows during addition

```go
func AddInt(a, b int) int {
    if a > math.MaxInt - b {
        panic("int overflow")
    }

    return a + b
}
```

### Detecting an integer overflow during multiplication

```go
func MultiplyInt(a, b int) int {
    if a == 0 || b == 0 {
        return 0
    }

    result := a * b
    if a == 1 || b == 1 {
        return result
    }
    if a == math.MinInt || b == math.MinInt {
        panic("integer overflow")
    }
    if result / b != a {
        panic("integer overflow")
    }

    return result
}
```

## Not understanding floating points.

In Go, there are two floating-point types: float32 and float64. The concept of a floating point was invented to solve the major problem with integers: their inability to represent fractional values. To avoid bad surprises, we need to know that floating-point arithmetic is an approximation of real arithmetic.

```go
var n float32 = 1.0001
fmt.Println(n*n)
```

We may expect this code to print the result of 1.0001\*1.0001 = 1.00020001, right? However, running it on most x86 processors prints 1.0002, instead. How do we explain that? We need to understand the arithmetic of floating points first.

Note that there's and infinite number of read values between math.SmallestNonzeroFloat64 (the float64 minimum) and math.MaxFloat64 (the float64 maximum). Conversely, the float64 type has a finite number of bits: 64. Because making infinite values fit into a finite space isn't possible, we have to work with approximations. Hence, we may lose precision.

## Not understanding slice length and capacity

It's pretty common for Go developers to mix slice length and capacity or not understand them thoroughly. Assimililating these two concepts is essential for efficiently handling core operations such as slice initialization and adding elements with append, copying, or slicing. This misunderstanding can lead to using slices suboptimally or even to memory leaks.

In Go, a slice is backed by an array. That means the slice's data is stored contiguously in an array data structure. A slice also handles the logic of adding an element if the backing array is full or shrinking.

Internally, a slice holds a pointer to the backing array plus an length and a capacity. **The length is the number of elements the slice contains, whereas the capacity is the number of elements in the backing array.**

```go
s := make([]int, 3, 6)
// [0, 0, 0, *, *, *]
```

The first argument, representing the length, is mandatory. However, the second argument representing the capacity is optional.

In this case, make creates an array of six elements (the capacity). But because the length was set to 3, Go initializes only the frist three elements. Also, because the slice is an []int type, the first three elements are initialized to the zeroed value of an int: 0. The remain elements are allocated but not yet used.

Accessing an element outside the length range is forbidden, even though it's already allocated in memory. For example, s[4] = 0 would lead to the following panic:

```txt
panic: runtime error: index out of range [4] with length 3
```

```go
s = append(s, 2)
```

This code appends to the existing s slice a new element. It uses the first grayed element (which was allocated but not yet used) to store element 2

[0, 0, 0, 2, *, *] => len = 4, cap = 6

The lenght of the slice is updated from 3 to 4 because the slice now contains four elements. Now, what happens if we add three more elements so that the backing array isn't large enough?

```go
s = append(s, 3, 4, 5)
fmt.Println(s)
```

[0, 0, 0, 2, 3, 4, 5]

Because an array is a fixed-size structure, it can store the new elements until element 4. When we want to insert element 5, the array is already full: Go internally creates another array by doubling the capacity, copying all the elements, and then inserting element 5.

Origin array: [0, 0, 0, 2, 3, 4]

New array: [0, 0, 0, 2, 3, 4, 5]

In Go, a slice grows by doubling its size until it contains 1,024 elements, after which it grows by 25%

The slice now references the new backing array. What will happen to the previous backing array? If it's no longer referenced, it's eventually freed by the GC, if allocated on the heap.

What happens with slicing? Slicing is an operation done on an array or a slice, providing a half-open range; the first index is included, whereas the second is excluded.

```go
s1 := make([]int, 3, 6) // [0, 0, 0, *, * , *]
s2 := s1[1:3] // [0, 0, *, *, *]
```

s1 and s2 reference the same backing array with different lengths and capacities.

First, s1 is created as a three-length, six-capacity slice. When s2 is created by slicing s1, both slices reference the same backing array. However, s2 starts from a different index, 1. Therefore, its length and capacity (a two-length, five-capacity slice) differ from s1. If we update s1[1] or s2[0], the change is made to the same array, hence, visible in both slices.

```go
s1 := make([]int, 3, 6)
s2 := s1[1:3]
fmt.Println(s1, s2)
s1[1] = 1
fmt.Println(s1, s2)
```

Now, that happens if we append an element to s2? Does the following code change s1 as well?

```go
s2 = append(s2, 2)
```

```go
s1 := make([]int, 3, 6)
s2 := s1[1:3]
s2 = append(s2, 2)
fmt.Println(s1, s2) // [0, 0, 0], [0, 0, 2]
s2[0] = 1
fmt.Println(s1, s2) // [0, 1, 0], [1, 0, 2]
s1 = s1[:4]
fmt.Println(s1, s2) // [0, 1, 0, 2], [1, 0, 2]
s1 = append(s1, 3)
fmt.Println(s1, s2) // [0, 1, 0, 2, 3], [1, 0, 2]
s2 = s2[:5]
fmt.Println(s1, s2) // [0, 1, 0, 2, 3], [1, 0, 2, 3, 0]
s1 = s1[:6]
fmt.Println(s1, s2) // [0, 1, 0, 2, 3, 0], [1, 0, 2, 3, 0]
s1[5] = 4
fmt.Println(s1, s2) // [0, 1, 0, 2, 3, 4], [1, 0, 2, 3, 4]
```

The backing array is internal and not available directly to the Go developer. The only exception is when a slice is created from slicing an existing array.

To summarize, the slice length is the number of available elements in the slice, whereas the slice capacity is the number of elements in the backing array. Adding an element to a full slice (length == capacity) leads to creating a new backing array with a new capacity, copying all the elements from the previous array, and updating the slice pointer to the new array.

## Inefficient slice initialization

```go
func convert(foos []Foo) []Bar {
    bars := make([]Bar, 0)

    for _, foo := range foos {
        // convert foo to bar and adds it to the slice
        bars = append(bars, fooToBar(foo))
    }
    return bars
}
```

The only change is to create bars with a capacity equal to n, the length of foos.

Internally, Go preallocates an array of n elements. Therefore, adding up to n elements means reusing the same backing array and hence reducing the number of allocations drastically. The second option is to allocate bars with a given length:

```go
func convert(foos []Foo) []Bar {
    n := len(foos)
    bars := make([]Bar, n)

    for i, foo := range foos {
        bars[i] = fooBar(foo)
    }
    return bars
}
```

Because we initialize the slice with a length, n elements are already allocated and initialized to the zero value of Bar. Hence, to set elements, we have to use, not append but bars[i]

Use index approach is better, capacity approach. But in some case, it is hard to read.

```go
func collectAllUserKeys(cmp Compare, tombstones []tombstoneWithLevel) [][]byte {
    keys := make([][]byte, 0, len(tombstones)*2)
    for _, v := range tombstones {
        keys = append(keys, t.Start.UserKey)
        keys = append(keys, t.End)
    }
}
```

Here, the conscious choice is to use a given capacity and append. What's the rationale? If we used a given length instead of a capacity, the code would be:

```go
func collectAllUserKeys(cmp Compare, tombstones []tombstoneWithLevel) [][]byte {
    keys := make([][]byte, len(tombstones)*2)
    for i, t := range tombstones {
        keys[i*2] = t.Start.UserKey
        keys[i*2 + 1] = t.End
    }
}
```

Notice how more complex the code to handle the slice index looks. Given that this function isn't performance sensitive, it was decided to favor the easiest option to read.

### Slices and conditions

If the future length of the slice isn't known precisely? For example, what if the length of the output slice depends on a condition?

```go
func convert(foos []Foo) []Bar {
    // bars init
    for _, foo := range foos {
        if something(foo) { // Add a Foo element only if a specific condition is valid
            // Add a bar element
        }
    }
    return bars
}
```

In this example, a Foo element is converted into a Bar and added to the slice only in a specific condition (if something(foo)). Should we initialize bars as an empty slice or with a given length or capacity?

There's no strict rule here. It's a traditional software problem: it is better to trade CPU or memory? Perhaps if something(foo) is true 99% of the cases, it's worth initilizing bars with a length or capacity. It depends on our use case.

Our options are to allocate a slice with either a given capacity or a given length. Of these two solutions, we have seen that the second tends to be slight faster. But using a given capacity and append caxn be easier to implement and read in some contexts.

### 22. Being confused about nil vs. empty slices

Go developers fairly frequently mix nil and empty slices. We may want to use one over the other depending on the use case. Meanwhile, some libraries make a distinction between the two. To be proficient with slices, we need to make sure we don't mix these concepts.

- A slice is empty if its length is equal to 0
- A slice is nil if it equals nil

```go
func main() {
    var s []string
    log(1, s) // 1: false, true
    s = []string(nil)
    log(2, s) // 2: false, true
    s = []string{}
    log(3, s) // 3: true, false
    s = make([]string, 0)
    log(4, s) // 4: true, false

}

func log(i int, s []string) {
    fmt.Printf("%d: empty=%t\tnil=%t\n", i, len(s) == 0, s == nil)
}
```

All the slices are empty, meaning the length equals to 0. Therefore, a nil slice is also an empty slice. However, only the first two are nil slices. There are two things to note:

- One of the main differences between a nil and an empty slice regards allocations. initializing a nil slice doesn't require any allocation, which isn't the case for an empty slice.
- Regardless of whether a slice is nil, calling the append built-in function works. For example,

```go
var s1 []string
fmt.Println(append(s1, "foo")) // [foo]
```

Consequently, if a function returns a slice, we shouldn't do as in other languages and return a non-nil collection for defensive reason. Because a nil slice doesn't require any allocation, we should favor returning a nil slice instead of an empty slice.

```go
func f() []string {
    var s []string
    if foo() {
        s = append(s, "foo")
    }
    if bar() {
        s = append(s, "bar")
    }
    return s
}
```

We should also mention that some libraries distinguish between nil and empty slices. This is the case, for example, with the encoding/json package. The following examples marshal two structs, one containing a nil slice and the second a non-nil, empty slices.

```go
func main() {
	p := person{
		Name: []string{},
	}
	data, _ := json.Marshal(p)
	fmt.Println(string(data))

	p = person{
		Name: []string(nil),
	}
	data, _ := json.Marshal(p)
	fmt.Println(string(data))
}

type person struct {
	Name []string `json:"name"`
}
```

Here a nil slice is marshaled as a null element, whereas a non-nil, empty slice is marshaled as an empty array.

To summarize, in Go, there is a distinction between nil and a empty slices. A nil slice equals nil, whereas an empty slice has a length of zero. A nil slice is empty, but an empty slice isn't necessarily nil. Meanwhile, a nil slice doesn't require any allocation.

- var s []string if we aren't sure about the final length and the slice can be empty
- []string(nil) as syntactic sugar to create a nil and empty slice
- make([]string, length) if the future length is known

## 23. Not properly checking if a slice is empty

What's the idomatic way to check if a slice contains elements? Not having a clear answer can lead to subtle bugs.

```go
func handleOperations(id string) {
    operations := getOperations(id)
    if operations != nil {
        handle(operations)
    }
}

func getOperations(id string) []float32 {
    operations := make([]float32, 0)
    if id == "" {
        return operations
    }

    // add elements to operations

    return operations
}
```

There is a problem with this code: getOperations never returns a nil slice; instead, it returns an empty slice. Therefore, the operations != nil check will always be true.

```go
func getOperations(id string) []float32 {
    operations := make([]float32, 0)
    if id == "" {
        return nil
    }

    // add elements to operations

    return operations
}
```

Instead of returning operations if id is empty, we return nil.

However, this approach doesn't work in all situations - we're not always in a context where we can change the callee. For example, if we use an external library, we won't create a pull request just to change empty into nil slices.

The solution is to check the length:

```go
func handleOperations(id string) {
    operations := getOperations(id)
    if len(operations) != 0 {
        handle(operations)
    }
}
```

- If the slice is nil, len(operations) != 0 is false.
- If the slice isn't nil but empty, len(operations) != 0 is also false.

This principle is the same with maps. To check if a map is empty, check its length, not whether it's nil.

## 24. Not making slice copies correctly

The copy built-in function allows copying elements from a source slice into a destination slice. Although it is a handy built-in function, Go developers sometimes misunderstand it. Let's look at a common mistake that results in copying the wrong number of elements.

```go
src := []int{0, 1, 2}
var dst []int
n := copy(dst, src)
fmt.Println(n, dst)
```

If we run this example, it prints [], not [0 1 2]. What did we miss?

To use copy effectively, it's essential to understand that the number of elements copied to the destination slice corresponds to the minimum between:

- The source slice's length
- The destination slice's length

In the previous example, src is the three-length slice, but dst is a zero-length slice because it is initialized to its zero value. Therefore, the copy function copies the minimum number of elements (between 3 and 0): 0 in this case. The resulting slice is then empty.

If we want to perform a complete copy, the destination slice must have a length greater than or equal to the source slice's length.

```go
src := []int{0, 1, 2}
dst := make([]int, len(src))
copy(dst, src)
fmt.Println(dst)
```

Copying elements from one slice to another is a reasonably frequent operation. When using copy, we must recall that the number of elements copied to the destination corresponds to the minimum between the two slice's lengths. Also bear in mind that other alternatives exist to copy a slice, so we shouldn't be surprised if we find them in a codebase.

## 25. Unexpected side effects using slide append

This section discusses a common mistake when using append, which may have unexpected side effects in some situations.

```go
s1 := []int{1, 2, 3}
s2 := s1[1:2]
s3 := append(s2, 10)
```

We initialize an s1 slice containing three elements, and s2 is created from slicing s1. Then we call append on s3. What should be the state of these slices at the end of this code?

s1 is a three-length, three-capacity slice, and s2 is a one-length, two-capacity slice, both backed by the same array we already mentioned. Adding an element using append checks whether the slice is full (length == capacity). If it is not full, the append function adds the element by updating the backing array and returning a slice having a length incremented by 1.

**Full slice expression**

```go
s[low:high:max]
```

```go
s1 := []int{1, 2, 3}
s2 := s1[1:2]
s2 = append(s2, 4)
fmt.Println(s1, s2) // [1, 2, 4], [2, 4]
s2 = s1[1:2:2]
s2 = append(s2, 5)
fmt.Println(s1, s2) // [1, 2, 4], [2, 5]
```

When passing s[:2:2], we can limit the range of effects to the first two elements. Doing so also prevents us from having to perform a slice copy.

When using slicing, we must remember that we can face a situation leading to unintended side effects. If the resulting slice has a length smaller than its capacity, append can mutate the original slice. If we want to restrict the range of possible side effects, we can use either a slice copy of the full slice expression, which prevents us from doing a copy.

## 26. Slices and memory leaks

That slicing an existing slice or array can lead to memory leaks in some conditions. We discuss two cases: one where the capacity is leaking and another that's related to pointers.

### Leaking capacity

For the first case, leaking capacity, let's imagine implementing a custom binary protocol. A message can contain 1 million bytes, and the first 5 bytes represent the message type. In our code, we consume these messages, and for auditing purposes, we want to store the latest 1000 message types in memory.

```go
func consumeMessage() {
    for {
        msg := receiveMessage()
        // Do something with msg
        storeMessageType(getMessageType(msg))
    }
}

func getMessaageType(msg []byte) []byte {
    // The slicing operation on msg using msg[:5] creates a five-length slice.
    // However, its capacity remains the same as the initial slice. The remaining elements are still allocated in memory, even if eventually msg is not referenced.
    return msg[:5] // len = 5, cap = cap(msg)
}
```

The backing array of the slice still contains 1 million bytes after the slicing operation. Hence, if we keep 1,000 messages in memory, instead of storing about 5KB, we hold about 1 GB.

What can do to solve this issue? We can make a slice copy instead of slicing msg:

```go
func getMessageType(msg []byte) []byte {
    cpyMsg := make([]byte, 5)
    copy(cpyMsg, msg)

    return cpyMsg
}
```

Because we perform a copy, msgType is a five-length, five capacity slice regardless of the size of the message received. Hence, we only store 5 bytes per message type.

**Full slice expressions and capacity leakage**

What about using the full slice expression to solve this issue? Let's look at this example:

```go
func getMessageType(msg []byte) []byte {
    return msg[:5:5]
}
```

By using runtime.Memstats, we can record statistics about the memory allocator, such as the number of bytes allocated on the heap:

```go
func printAlloc() {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    fmt.Printf("%d KB\n", m.Alloc/1024)
}
```

```go
var leaker [][]byte

func main() {
	printAlloc()

	for i := 0; i < 10; i++ {
		msgs := make([]byte, 100_000)
		leaker = append(leaker, msgs[:1])
	}
	runtime.GC()
	printAlloc()
}

func printAlloc() {
	var m runtime.MemStats
	// ReadMemStats populates m with memory allocator statistic
	// The returned memory allocator statistics are up to date as of the
	// call to ReadMemStats. This is in constrast with a heap profile
	// which is a snapshot as of the most recently completed garbage
	// collection cycle.
	runtime.ReadMemStats(&m)
	fmt.Printf("%d KB\n", m.Alloc/1000)
}
```

Using full slice expression isn't a valid option (unless a future update of Go tackles this).

Remember that slicing a large slice or array can lead to potential high memory consumption. The remaining space won't be reclaimed by the GC, and we can keep a large backing array despite using only a few elements. Using a slice copy is the solution to prevent such a case.

## Slice and pointers

We have seen that slicing can cause a leak because of the slice capacity. But what about the elements, which are still part of the backing array but outside the length range? Does the GC collect them?

```go
type Foo struct {
    v []byte
}
```

We want to check the memory allocations after each step as follows:

```go
1. Allocate a slice of 1.000 Foo elements
2. Iterate over each Foo element, each for each one, allocate 1MB for the v slice.
3. Call Call keepFirstTwoElementsOnly, which returns only the frist two elements using slicing, and then call a GC.
```

```go
type Foo struct {
	v []byte
}

func main() {
	foos := make([]Foo, 1_000)

	for i := 0; i < len(foos); i++ {
		foos[i] = Foo{
			v: make([]byte, 1024*1024),
		}
	}
	printAlloc()
	two := keepFirstTwoElementsOnly(foos)
	runtime.GC()
	printAlloc()
	runtime.KeepAlive(two)
}

func keepFirstTwoElementsOnly(foos []Foo) []Foo {
	return foos[:2]
}

func printAlloc() {
	var m runtime.MemStats
	// ReadMemStats populates m with memory allocator statistic
	// The returned memory allocator statistics are up to date as of the
	// call to ReadMemStats. This is in constrast with a heap profile
	// which is a snapshot as of the most recently completed garbage
	// collection cycle.
	runtime.ReadMemStats(&m)
	fmt.Printf("%d KB\n", m.Alloc/1000)
}
```

If the element is a pointer or a struct with pointer fields, the elements won't be reclaimed by the GC. In our example, because Foo contains a slice (and a slice is a pointer on top of a backing array), the remaining 988 Foo elements and their slice aren't reclaimed. Therefore, even though these 998 elements can't be accessed, they stay in memory as long as the variable returned by keepFirstTwoElementsOnly is referenced.

What are the options to ensure that we don't leak the remaining Foo elements? The first option, again, is to create a copy of the slice:

```go
func keepFirstTwoElementsOnly(foos []Foo) []Foo {
    res := make([]Foo, 2)
    copy(res, foos)

    return res
}
```

There's a second option if we want to keep the underlying capacity of 1000 elements, which is mark the slices of the remaining elements explicityly as nil:

```go
func keepFirstTwoElementsOnly(foos []Foo) []Foo {
    for i := 2; i < len(foos); i++ {
        foos[i].v = nil
    }
}
```

Here, we return a 2-length, 1000 capacity slice, but we set the slices of the remaining elements to nil. Hence, the GC can collect the 998 backing arrays.

Which option is the best? If we don't want to keep the capacity at 1000 elements, the first option is probably the best. However, the decision can also depend on the proportion of the elements.

Option 1: Iterate and copy elements from 0 to i - 1 (i closer to 0)

Option 2: Set to nil the slices from elements i to n (i closer to n)

## 27. Inefficient map initialization

### Concepts

A map provides an unordered collection of key-value pairs in which all the keys are distinct. In Go, a map is based on the hash table. Internally, a hash table is an array of buckets, and each bucket is a pointer to an array of key-value pairs.

Each operation (read, update, insert, delete) is done by associating a key to an array index. This step relies on a hash function. Hash("two") returns 0; hence, the element is stored in the bucket referenced by the array index 0.

In the case of insertion into a bucket that already full (bucket overflow), Go creates another bucket of eight elements and links the previous bucket to it.

Regarding reads, updates, and deletes, Go must calculate the corresponding array index. Then Go iterates sequentially over all the keys untils it finds the provided one. Therefore, the worst-case time complexity for these operations is O(p), where p is the total number of elements in the buckets (one bucket by default, multiple buckets in case of overflows).

### Initialization

```go
m := map[string]int{
    "1": 1,
    "2": 2,
    "3": 3,
}
```

Internally, this map is backed by an array consisting of a single entry: hence a single bucket. What happens if we add 1 million elements? In this case, a single entry won't be enough because finding a key would mean, it the worst case, going over thousands of buckets. This is why a map should be able to grow automatically to cope with the number of elements.

When a map grows, it doubles its number of buckets. What are the conditions for a map to grow?

- The average number of items in the buckets (called the load factor) is greater than a constant value. This constant equals 6.5 (but it may change in future versions because it's internal to Go).
- Too many buckets have overflowed (containing more than eight elements)

When a map grow, all the keys are dispatched again to all the buckets. This is why, in the worst-case scenario, inserting a key can be an O(n) operation, with n being the total number of elements in the map.

We saw that when using slices, if we knew up front the number of elements to be added to the slice, we could initialize it with a given size of capacity. This avoids having to keep repeating the costly slice growth operation. The idea is similar for maps. For example, if we want to initialize a map that will contain 1 million elements, it can be done this way:

```go
m := make(map[string]int, 1_000_000)
```

With a map, we can give the built-in function make only an initial size and not a capacity, as with slices: hence, a single argument.

By specifying a size, we provide a hint about the number of elements expected to go into the map. Internally, the map is created with an approriate number of buckets to store 1 million elements. This saves a lot of computation time because the map won't have to create buckets on the fly and handle rebalancing buckets.

Also, specifying a size n doesn't mean making a map with a maximum number of n elements. We can still add more than n elements if needed. Instead, it means asking the Go runtime to allocate a map with room for at least n elements, which is helpful if we already know the size up front.

Therefore, just like with slices, if we know up front the number of elements a map nil will contain, we should create it by providing an initial size. Doing this avoids potential map growth, which is quite heavy computation-wise because it requires reallocating enough space and rebalancing all the elements.

## 28. Maps and memory leaks

We need to understand some important characteristics of how a map grows and shrinks

```go
func main() {
	var n int = 1e6
	m := make(map[int][128]byte)
	printAlloc()

	for i := 0; i < n; i++ {
		m[i] = [128]byte{}
	}
	printAlloc()

	for i := 0; i < n; i++ {
		delete(m, i)
	}
	fmt.Println(len(m))

	runtime.GC()
	printAlloc()
	runtime.KeepAlive(m)
}
```

We allocate an empty map, add 1 million elements, remove 1 million elements, and then run a GC. We also make sure to keep a reference to the map using runtime. KeepAlive so that the map isn't collected as well.

At first the heap size is minimal. Then it grows significantly after having added 1 milion elements to the map. But if we expected the heap size to decrease after removing all the elements, this isn't how maps work in Go. In the end, even though the GC has collected all the elements, the heap size is still 293MB. So the memory shrunk, but not as we might have expected.

A map is composed of eight-element buckets. Under the hood, a Go map is pointer to a runtime.hmap struct. This struct contains multiple fields, including a B field, giving the number of buckets in the map:

```go
type hmap struct {
    B uint8 // log_2 of buckets, can hold up loadFactor * 2^B items
}
```

After adding 1 million elements, the value of B equals to 18, which mean 2^18 = 262144 buckets. When we remove 1 million elements, what's the value of B? Still 18. Hence, the map still contains the same number of buckets. When we remove 1 million elements, what's the value of B? Still 18. Hence, the map still contains the same number of buckets.

The reason is that the number of buckets in a map cannot shrink. Therefore, removing elements from a map doesn't impact the number of existing buckets; it just zeroes the slots in the buckets. A map can only grow and have more buckets; it never shrinks.

The size allocate is decrease, but running the GC didn't impact the map itself. Even the number of extra buckets (the buckets created because the overflows) remains the same.

Let's take a step back and discuss when the fact that a map cannot shrink can be a problem. Imagine building a cache using map[int][128]byte. This map holds per customer ID (the int), a sequence of 128 bytes. Now, suppose we want to save the last 1,000 customers. The map size will remain constant, so we shouldn't worry about the fact that a map cannot shrink.

However, let's say we want to store one hour of data. Meanwhile, our company has decided to have a big promotion for Black Friday: in one hour, we may have millions of customers connected to our system. But a few millions of customers connected to our system. But a few days after Black Friday, our map will contain the same number of buckets as during the peak time. This explains why we can experience high memory consumption that doesn't significantly decrease in such a scenario.

What are the solutions if we don't want to manually restart our service to clean the amount of memory consumed by the map? One solution could be to re-create a copy of the current map at regular pace. For example, every hour, we can build a new map, copy all the elements, and release the previous one. The main drawback of this option is that following the copy and until the next garbage collection, we may consume twice the current memory for a short period.

Another solution would be to change the map type to store an array pointer: map[int]\*[128]byte. It doesn't solve the fact that we will have a significantly number of buckets; however, each bucket entry will reserve the size of a pointer for the value instead of 128 bytes (8 bytes on 64-bit systems and 4 bytes on 32-bit system).

| Step                                 | map[int][128]byte | map[int]\*[128]byte |
| ------------------------------------ | ----------------- | ------------------- |
| Allocate an empty map                | 0 MB              | 0 MB                |
| Add 1 million elements               | 461MB             | 182MB               |
| Remove all the elements and run a GC | 293MB             | 38MB                |

As we can see, after removing all the elements, the amount of required memory is signnificantly less than with a map[int]\*[128]byte type. Also, in this case, the amount of required memory is less significant during peak times due to some optimizations to reduce the memory consumed.

As we have seen, adding n elements to a map and then deleting all the elements means keeping the same number of buckets in memory. So, we must remember that because a Go map can only grow in size, so does its memory consumption. There is no automated strategy to shrink it. If this leads to high memory consumption, we can try different options such as forcing Go to re-create the map or using pointers to check if it can be optimized.

## 29. Comparing values incorrectly

Comparing values is a common operation software development.

It's essential to understand how to use == and != to make comparisons effectively. We can use these operators on operands that are comparable:

- Booleans: Compare whether two Booleans are equal.
- Numerics (int, float, and complex types): Compare whether two numerics are equal.
- Strings: Compare whether two strings are equal.
- Channels: Compare whether two channels were created by the same call to make or if both are nil.
- Interfaces: Compare whether two interfaces have identical dynamic types and equal dynamic values of if both are nil.
- Pointers: Compare whether two pointers point to the same value in memory or if both are nil.
- Structs and arrays: Compare whether they are composed of similar types.

```go
type Printer interface {
	Print() any
}
type PrinterV2 interface {
	Print() any
}

func main() {
	var printer Printer
	var printerV2 PrinterV2
	fmt.Println(printer == printerV2)
}
```

```go
var cust1 any = customer{id: "x", operations: []float64{1.}}
var cust2 any = customer{id: "x", operations: []float64{1.}}

fmt.Println(cust1 == cust2)
```

This code compiles. But as both types can't be compared because the customer struct contains a slice field, it leads to an error at run time:

```go
panic: runtime error: comparing uncomparable type main.customer
```

With these behaviors in mind, what are the options if we have to compare two slices, two maps, or two structs containing noncomparable types? If we stick with the standard library one option is to use run-time reflection with the reflect package.

Reflection is a form of metaprogramming, and it refers to the ability of an application to introspect and modify its struct and behavior. For example, in Go, we can use reflect.DeepEqual. This function reports whether two elements are deeply equal by recursively traversing two values.

**reflect.DeepEqual has a specific behavior depending on the type we provide. Before using it, read the documentation carefully.**

reflect.DeepEqual is about 100 times slower than ==. This might be reason to favor using it in the context of testing instead of at runtime.

In general, we should remember that the == operator is pretty limited. For example, it doesn't work with slices and maps. In most cases, using reflect.DeepEqual is a solution, but the main catch is the performance penalty. However, if the performance is crucial at runtime, implementing our custom method might be the best solution.

One additional note: we must remember that the standard library has some existing comparison methods. For example, we can use the optimized bytes.Compare function to compare two slices of bytes. Before implementing a customer method, we need to make sure we don't reinvent the wheel.

## Summary

- When reading existing code, bear in mind that integer literals starting with 0 are octal numbers. Also, to improve readability, make octal integers explicit by prefixing them with 0o.
- Because integer overflows and underflows are handled silently in Go, you can implement your own functions to catch them.
- Making floating-point comparisons within a given delta can ensure that your code is portable.
- Understanding the difference between the slice length and capacity should be part a of Go developer's core knowledge. The slice length is the number of available elements in the slice, whereas the slice capacity is the number of elements in the backing array.
- When creating a slice, initialize it with a given length and capacity if its length is already known. This reduces the number of allocations and improves performance. The same logic goes for maps, and you need to initialize their size.
- Using copy or the full slice expression is a way to prevent append from creating conflicts if two different functions use slices backed by the same array. However, only a slice copy prevents memory leaks if you want to shrink a large slice.
- To copy one slice to another using built-in function, remember that the number of copied elements corresponds to the minimum between the two slice's lengths.
- Working with a slice of pointers or structs with pointer fields, you can avoid memory leaks by marking as nil the elements excluded by a slicing operation.
- To prevent common confusions such as when using the encoding/json or the reflect package, you need to understand the difference between nil and empty slices. Both are zero-length, zero-capacity slices, but only a nil slice doesn't require allocation.
- To check if a slice doesn't contain any element, check its length. This check works regardless of whether the slice is nil or empty. The same goes for maps.
- To design unambiguous APIs, you shouldn't distinguish between nil and empty slices.
- A map can always grow in memory, but it never shrinks. Hence, if it leads to some memory issues, you can try different options, such as forcing Go to re-create the map or using pointers.
- To compare types in Go, you can use the == and != operators if two types are comparable. Otherwise, you either use reflect.DeepEqual and pay the price of reflections and libraries.
