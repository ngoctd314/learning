# 10. The standard library

## 75. Providing a wrong time duration

The standard library provides common functions and methods that accept a time.Duration. However, because time.Duration is an alias for the int64 type, newcommers to the language can get confused and provide a wrong duration.

```go
func main() {
	ticker := time.NewTicker(1000)
	for {
		select {
		case <-ticker.C:
			fmt.Println("Do something")
		}
	}
}
```

If we run this code, we notice that ticks aren't delivered every second; they are delivered every microsecond.

Because time.Duration is based on the int64 type, the previous code is correct since 1000 is a valid int64. But time.Duration represents the elapsed time between two instants in nanoseconds. Therefore, we provided NewTicker with a duration of 1000 nanoseconds = 1 microsecond.

This mistake happens frequently. Indeed, standard libraries in languages such as Java and Javascript sometimes ask developers to provide durations in milliseconds.

Futhermore, if we want to purposely create a time.Ticker with an interval of 1 microsecond, we shouldn't pass an int64 directly. We should instead always use the time.Duration API to avoid possible confusion:

```go
func main() {
	ticker := time.NewTicker(1000 * time.Millisecond)
	for {
		select {
		case <-ticker.C:
			fmt.Println("Do something")
		}
	}
}
```

This is not the most complex mistake in this book, but developers with a background in other languages can easily fall into the trap of believing that milliseconds are expected for the functions and methods in the time package. We must remember to use the time.Duration API and provide an int64 alongside a time unit.

## 76. time.After and memory leaks

time.After(time.Duration) is a convenient function that returns a channel and waits for a provided duration to elapse before sending a message to this channel. Usually, it's used in concurrent code; otherwise, if we want to sleep for a given duration, we can use time.Sleep(time.Duration). The advantage of time.After is that it can be used to implement scenarios such as "If i don't receive any message in this channel for 5 seconds, it will... " But codebases ofter include calls to time.After in a loop, which, as we describe in this section, may be a root cause of memory leaks.

Let's consider the following example. We will implement a function that repeatedly consumes messages from a channel. We also want to log a warning if we haven't received any messages for more than 1 hour. Here is a possible implementation:

```go
func consumer(ch <-chan Event) {
	for {
		select {
		case event := <-ch:
			fmt.Println("recv event: ", event)
		case <-time.After(time.Hour):
			fmt.Println("warning: no message received")
			return
		}
	}
}
```
Here, we use select in two cases: receiving a message from ch and after 1 hour without messages (time.After is evaluated during each iteration). At first sight, this code looks OK. However, it may lead to memory usage issues.

```go
func main() {
	ch := make(chan Event)
	go func() {
		for i := 0; ; i++ {
			ch <- Event{}
		}
	}()
	consumer(ch)
}

type Event struct{}

func consumer(ch <-chan Event) {
	for {
		printAlloc()
		select {
		case event := <-ch:
			fmt.Println("recv event: ", event)
		case <-time.After(time.Hour):
			fmt.Println("warning: no message received")
			return
		}
	}
}

func printAlloc() {
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	fmt.Printf("Alloc = %v MiB", bToMb(m.Alloc))
	fmt.Printf("\tTotalAlloc = %v MiB\n", bToMb(m.TotalAlloc))

}
func bToMb(b uint64) uint64 {
	return b / 1024 / 1024
}
```
If we run this program, we see that Alloc always incre. After a few minutes, Alloc memory will reach to GB. Application will OOM

```go
func consumer(ch <-chan Event) {
	for {
		printAlloc()
		select {
		case event := <-ch:
			fmt.Println("recv event: ", event)
		// case <-time.After(time.Hour):
		// 	fmt.Println("warning: no message received")
		// 	return
		}
	}
}
```
We comment <-time.After case, Alloc will be ~ 0 MiB. Why this happens? 

As we said, time.After returns a channel. We may expect this channel to be closed during each loop iteration, but this isn't the case. The resources created by time.After (including the channel) are released once the timeout expires and use memory until that happens. In Go 1.15, about 200 bytes of memory are used per call to time.After. If we receive a significant volume of messages, such as 5 million per hour, our application will consume 1 GB of memory to store the time.After resources.

Can we fix this issue by closing the channel programmatically during each iteration? No. The returned channel is a <- chan time.Time, meaning it is a receive-only channel that can't be closed.

We have several options to fix our example. The first is to use a context instead of time.After: 

```go
func consumer(ch <-chan Event) {
	for {
		printAlloc()

		ctx, cancel := context.WithTimeout(context.Background(), time.Hour)
		select {
		case event := <-ch:
			cancel()
			fmt.Println("recv event: ", event)
		case <-ctx.Done():
			cancel()
			fmt.Println("warning: no message received")
			return
		}
	}
}
```

The downside of this approach is that we have to re-create a context during every single loop iteration. Creating a context isn't the most lightweight operation in Go: for example, it requires creating a channel. Can we do better?

The second option comes from the time package:

time.NewTimer. This function creates a time.Timer struct that exports the following:

```go
type Timer struct {
    // which is the internal timer channel
	C            <-chan time.Time
	r runtimeTimer
}

// Method to reset the duration
func (Timer) Reset(d time.Duration) {} 

// Method to stop timer
func(Timer) Stop() {}
```

We should note that time.After also relies on time.Timer. However, it only returns the c field, so we don't have access to the Reset method:

```go
package time

func After(d Duration) <- chan Time {
    return NewTimer(d).C
}
```

```go
func main() {
	ch := make(chan Event)
	go func() {
		for i := 0; ; i++ {
			ch <- Event{}
		}
	}()
	consumer(ch)
}

type Event struct{}

func consumer(ch <-chan Event) {
	for {
		timerDuration := time.Hour
		timer := time.NewTimer(timerDuration)

		for {
			printAlloc()
			timer.Reset(timerDuration)
			select {
			case event := <-ch:
				fmt.Println("recv event: ", event)
			case <-timer.C:
				fmt.Println("warning: no message received")
				return
			}
		}
	}
}

func printAlloc() {
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	fmt.Printf("Alloc = %v MiB", bToMb(m.Alloc))
	fmt.Printf("\tTotalAlloc = %v MiB\n", bToMb(m.TotalAlloc))

}
func bToMb(b uint64) uint64 {
	return b / 1024 / 1024
}
```

In this implementation, we keep a recurring action during each loop iteration: calling the Reset method. However, calling Reset is less cumbersome than having to create a new context every time. It's faster and puts less pressure on the garbage collector because it doesn't require any new heap allocation. Therefore, using time.Timer is the best possible solution for our initial problem.

Using time.After is a loop isn't the only case that may lead to a peak in memory consumption. The problem relates to code that is repeatedly called. A loop is one case, but using time.After in an HTTP handler function can lead to the same issues because the function will be called multiple times.

In general, we should be cautions when using time.After. Remember that the resources created will only be released when the timer expires. When the call to time.After is repeated (for example, in a loop, a Kafka consumer function or an HTTP handler), it may lead to a peak in memory consumption.

## 77. Common JSON handling mistakes

### Unexpected behavior due to type embedding

Let's discuss another potential impact of type embedding that can lead to unexpected marshaling/unmarshaling results.

```go
type Event struct {
    ID int
    time.Time
}
```
Because time.Time is embedded, in the same way we described previously, we can access the time.Time methods directly at the Event level: for example, event .Second(). What are the possible impacts of embedded fields with JSON marshaling? Let's find out in the following example. 

```go
type Event struct {
	ID int
	time.Time
}

func main() {
	e := Event{
		ID:   1234,
		Time: time.Now(),
	}
	data, _ := json.Marshal(e)
	fmt.Println(string(data))
}
```

Output missing ID field. How can we explain this output? What happened to the ID field and the 1234 value? Because this field is exported, it should have been marshaled. To understand this problem, we have to highlight two points.

If an embedded field type implements an interface, the struct containing the embedded field will also implement this interface. Second, we can change the default marshaling behavior by marking a type implement the json.Marshaler interface. This interface contains a single MarshalJSON function:

```go
type Marshaler interface {
    MarshalJSON() ([]byte, error)
}
```

Here is an example with custom marshaling:

```go
type foo struct{}

func (foo) MarshalJSON() ([]byte, error) {
	return []byte(`"foo"`), nil
}

func main() {
	b, err := json.Marshal(foo{})
	if err != nil {
		panic(err)
	}
	fmt.Println(string(b))
}
```

Having clarified these two points, let's get back to the initial problem with the Event struct:

```go
type Event struct {
    ID int
    time.Time
}
```

We have to know that time.Time implements the json.Marshaler interface. Because time.Time is an embedded field of Event, the compiler promotes its methods. Therefore, Event also implements json.Marshaler.

Consequently, passing an Event to json.Marshal uses the marshaling behavior provided by time.Time instead of the default behavior. This is why marshaling an Event leads to ignoring the ID field.

To fix this issue, there are two main possibles. First, we can add a name so the time.Time field is no longer embedded:

```go
type Event struct {
    ID int
    Time time.Time
}
```

If we want to keep the time.Time field embedded, the other option is to make Event implement the json.Marshaler interface:

```go
func (e Event) MarshalJSON() ([]byte, error) {
    return json.Marshal(
        struct {
            ID int
            Time time.Time
        }{
            ID: e.ID,
            Time: e.Time,
        },
    )
}
```
We should be careful with embedded fields. While promoting the fields can convenient, it can also lead to subtle bugs because it can make the parent struct implement interfaces without a clear signal. Again, when using embedded fields, we should clearly understand the possible side effects.

When an built-in function receive an any argument. You need to check how to use this argument. json.MarshalJSON(v any) implement

```go
if t.Kind() != reflect.Pointer && allowAddr && reflect.PointerTo(t).Implements(marshalerType) {
    return newCondAddrEncoder(addrMarshalerEncoder, newTypeEncoder(t, false))
}
if t.Implements(marshalerType) {
    return marshalerEncoder
}
if t.Kind() != reflect.Pointer && allowAddr && reflect.PointerTo(t).Implements(textMarshalerType) {
    return newCondAddrEncoder(addrTextMarshalerEncoder, newTypeEncoder(t, false))
}
if t.Implements(textMarshalerType) {
    return textMarshalerEncoder
}
```

### JSON and the monotonic clock
