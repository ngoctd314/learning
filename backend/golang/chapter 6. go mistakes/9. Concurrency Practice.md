# Concurrency: Practice

This chapter covers

- Preventing common mistakes with goroutines and channels
- Understanding the impacts of using standard data structures alongside concurrent code
- Using the standard library and some extensions
- Avoiding data races and deadlocks

## Propagating an inappropriate context

Contexts are omnipresent when working with concurrency in Go, and in many situations, it may be recommended to propagate them. However, context  propagation can sometimes lead to subtle bugs, preventing subfunction from being correctly executed.

Let's consider the following example. We expose an HTTP handler that performs some tasks and returns a response. But just before returning the response, we also want to send it to a Kafka topic. We don't want to penalize the HTTP consumer latency-wide, so we want the publish action to be handled asynchronously wihtin a new goroutine. We assume that we have at our disposal a publish function that accepts a context so the action of publishing a message can be interrupted if the context is canceled.

```go
func handler(w http.ResponseWriter, r *http.Request) {
    response, err := doSomeTask(r.Context(), r)
    if err != nil {
        return
    }

    go func() {
        err := publish(r.Context(), response)
    }()

    writeResponse(response)
}
```

We have to know that the context attached to an HTTP request can be cancel in different conditions:

- When the client's connection closes
```go
func main() {
	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		ctx := r.Context()
		go func() {
			select {
			case <-ctx.Done():
				fmt.Printf("ctx.Err() %s\n", ctx.Err())
            default:
                publish("msg")
			}
		}()
		time.Sleep(time.Second * 5)

		w.Write([]byte("OK"))
	})
	http.ListenAndServe(":8080", nil)
}
```

- In the case of HTTP/2 request, when the request is canceled.
- When the response has been written back to the client.

```go
func main() {
	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		ctx := r.Context()
		go func() {
			select {
			case <-ctx.Done():
				fmt.Printf("ctx.Err() %s\n", ctx.Err())
			}
            default:
                publish("msg")
		}()

		w.Write([]byte("OK"))
	})
	http.ListenAndServe(":8080", nil)
}
```

In the first two cases, we probably handle things correctly. For example, if we get a response from doSomeTask but the client has closed the connection, it's probably OK to call publish with a context already canceled so the message isn't published. But what about the last case?

When the response has been written to the client, the context associated with the request will be canceled. Therefore, we are facing a race condition:

- If the response is written after the Kafka publication, we both return a response and publish a message successfully
- However, if the response is written before or during the Kafka publication, the message shouldn't be published.

In the latter case, calling publish will return an error because we returned the HTTP response quickly.

How can we fix this issue? One idea is to propagate the parent context. Instead, we would call publish with an empty context:

```go
// uses an empty context instead of the HTTP request context
err := publish(context.Background(), response)
```

Here, that would work. Regardless of how long it takes to write back the HTTP response, we can call publish.

But what if the context contained useful values? For example, if the context contained a correlation ID used for distributed tracing, we could correlate the HTTP request and the Kafka publication. Ideally, we would like to have a new context that is detached from the potential parent cancellation but still conveys the values.

The standard package doesn't provide an immediate solution to this problem. Hence, a possible solution is to implement our own Go context similar to the context provided, except that it doesn't carry the cancellation signal.

```go
type Context interface {
    Deadline() (deadline time.Time, ok bool)
    Done() <-chan struct{}
    Err() error
    Value(key any) any
}
```
The context's deadline is managed by the Deadline method and the Cancellation signal is managed via the Done and Err methods. 

```go
type detactContext struct {
	context.Context
}

func (d detactContext) Deadline() (time.Time, bool) {
	return time.Time{}, false
}

func (d detactContext) Done() <-chan struct{} {
	return nil
}

func (d detactContext) Err() error {
	return nil
}
```

Except for the Value method that calls the parent context to retrieve a value, the other methods return a default value so the context is never consider expired or canceled.

```go
err := publish(detach{ctx: r.Context()})
```

Now the context passed to publish will never expire or be canceled, but it will carry the parent context's values.

In summary, propagating a context should be done cautionsly. We illustrated that in this section with an example of handling an asynchronous action based on a context associated with an HTTP request. Because the context is canceled once we return the response, the asynchronous action also be stopped unexpectedly. Let's bear in mind the impacts of propagating a given context and, if necessary, that is always of propagation a given context and, if necessary, that it is always possible to create a custom context for a specific action.

## 62. Starting a goroutine without knowing when to stop it

Goroutines are easy and cheap to start, so easy and cheap that we may not necessarily have a plan for when to stop a new goroutine, which can lead to leaks. Not knowing when to stop a goroutine is a design issue and a common concurrency mistake in Go.

In terms of memory, a goroutine starts with a minimum stack size of 2 KB, which can grow and shrink as needed (the maximum stack size is 1 GB on 64-bit and 250 MB on 32-bit). Memory-wise, a goroutine can also hold variable references allocated to the heap. Meanwhile, a goroutine can hold resources such as HTTP or database connections, open files, and network sockets that should eventually be closed gracefully.

If goroutine is leaked, these kinds of resources will also be leaked.

Let's look at an example in which the point where a goroutine stops is unclear. Here, a parent goroutine calls a function that returns a channel and then creates a new goroutine that will keep receiving messages from this channel:

```go
ch := foo()
go func() {
    for v := range ch {
        // ...
    }
}()
```

The created goroutine will exit when ch is closed. But do we know exactly when this channel will be closed? It may not be evident, because ch is created by the foo function. If the channel is never closed, it's a leak. So, we should always be cautions about the exit points of a goroutine and make sure one is eventually reached.

```go
func main() {
    newWatcher()
}

type watcher struct {} 

func newWatcher() {
    w := watcher{}
    go w.Watch()
}
```

The problem with this code is that when the main goroutine exits (perhaps because of an OS signal or because it has a finite workload), the application is stopped. Hence, the resources created by watcher aren't closed gracefully. How can we prevent this from happening?

One option could be pass to newWatcher a context that will be canceled when main returns:

```go
func main() {
    ctx, cancel := context.WithCancel()
    defer cancel()

    newWatcher(ctx)
}

func newWatcher(ctx context.Context) {
    w := watcher{}
    go w.watch(ctx)
}
```

We propagate the context created to the watch method. When the context is canceled, the watcher struct should close its resources. However, can we guarantee that watch will have time to do so? Absolutely not - and that's a design flaw.

The problem is that we used signaling to convey that a goroutine had to be stopped. We didn't block the parent goroutine until the resources had been closed.

```go
func main() {
    w := newWatcher()
    defer w.Close()

    // Run the application
}

func newWatcher() watcher {
    w := watcher{}
    go w.watch()
    return w
}

func (w watcher) close() {
    // close the resources
}
```
Watcher has a new method: close. Instead of signaling watcher that it's time to close its resources, we now call this close method, using defer to guarantee that the resources are closed before the application exits.

In summary, let's be mindful that a goroutine is a resource like any other that must eventually be closed to free memory or other resources. Starting a goroutine without knowing when to stop it is a design issue. Whenever a goroutine is started, we should have a clear plain about when it will stop. Last but not least, if a goroutine creates resources and its lifetime is bound to the lifetime of the application, it's probably safer to wait for this goroutine to complete before existing the application. This way, we can ensure that the resources can be freed.

## 63. Not being careful with goroutines and loop variables

Mishandling goroutines and loop variables is probably one of the most common mistakes by Go developers when writing concurrent applications.

```go
s := []int{1, 2, 3}

for _, i := range s {
    go func() {
        fmt.Print(i)
    }()
}
```

The output of this code isn't deterministic. For example, sometimes it print 233 and other times 333. What's the reason?

In this example, we create new goroutines from a clousure. As a reminder, a closure is a function value that references variables from outside its body: here, the i variable. We have to know that when a closure goroutine is executed, it doesn't capture the values when the goroutine is created. Instead, all the goroutines refer to the exact same variable. When a goroutines runs, it prints the value of i at the time fmt.Print is execute. Hence, i may have been modified since the goroutine was launched.

What are the solutions if we want each closure to access the value of i when the goroutine is created? The first option, if we want to keep using a closure, involves creating a new variale:

```go
for _, i := range s {
    val := i
    go func() {
        fmt.Print(val)
    }()
}
```

The second option no longer relies on a closure and instead uses an actual function

```go
for _, i := range {
    go func(val int) {
        fmt.Println(val)
    }(i)
}
```

We still execute an anonymous function within a new a goroutine (we don't run go f(i)), but this time it isn't a closure. The function doesn't reference val as a variable from outside its body; val is now part of the function input.

## 64. Expecting deterministic behavior using select and channels


