# Concurrency: Practice

This chapter covers

- Preventing common mistakes with goroutines and channels
- Understanding the impacts of using standard data structures alongside concurrent code
- Using the standard library and some extensions
- Avoiding data races and deadlocks

## Propagating an inappropriate context

Contexts are omnipresent when working with concurrency in Go, and in many situations, it may be recommended to propagate them. However, context  propagation can sometimes lead to subtle bugs, preventing subfunction from being correctly executed.

Let's consider the following example. We expose an HTTP handler that performs some tasks and returns a response. But just before returning the response, we also want to send it to a Kafka topic. We don't want to penalize the HTTP consumer latency-wide, so we want the publish action to be handled asynchronously wihtin a new goroutine. We assume that we have at our disposal a publish function that accepts a context so the action of publishing a message can be interrupted if the context is canceled.

```go
func handler(w http.ResponseWriter, r *http.Request) {
    response, err := doSomeTask(r.Context(), r)
    if err != nil {
        return
    }

    go func() {
        err := publish(r.Context(), response)
    }()

    writeResponse(response)
}
```

We have to know that the context attached to an HTTP request can be cancel in different conditions:

- When the client's connection closes
```go
func main() {
	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		ctx := r.Context()
		go func() {
			select {
			case <-ctx.Done():
				fmt.Printf("ctx.Err() %s\n", ctx.Err())
            default:
                publish("msg")
			}
		}()
		time.Sleep(time.Second * 5)

		w.Write([]byte("OK"))
	})
	http.ListenAndServe(":8080", nil)
}
```

- In the case of HTTP/2 request, when the request is canceled.
- When the response has been written back to the client.

```go
func main() {
	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		ctx := r.Context()
		go func() {
			select {
			case <-ctx.Done():
				fmt.Printf("ctx.Err() %s\n", ctx.Err())
			}
            default:
                publish("msg")
		}()

		w.Write([]byte("OK"))
	})
	http.ListenAndServe(":8080", nil)
}
```

In the first two cases, we probably handle things correctly. For example, if we get a response from doSomeTask but the client has closed the connection, it's probably OK to call publish with a context already canceled so the message isn't published. But what about the last case?

When the response has been written to the client, the context associated with the request will be canceled. Therefore, we are facing a race condition:

- If the response is written after the Kafka publication, we both return a response and publish a message successfully
- However, if the response is written before or during the Kafka publication, the message shouldn't be published.

In the latter case, calling publish will return an error because we returned the HTTP response quickly.

How can we fix this issue? One idea is to propagate the parent context. Instead, we would call publish with an empty context:

```go
// uses an empty context instead of the HTTP request context
err := publish(context.Background(), response)
```

Here, that would work. Regardless of how long it takes to write back the HTTP response, we can call publish.

But what if the context contained useful values? For example, if the context contained a correlation ID used for distributed tracing, we could correlate the HTTP request and the Kafka publication. Ideally, we would like to have a new context that is detached from the potential parent cancellation but still conveys the values.

The standard package doesn't provide an immediate solution to this problem. Hence, a possible solution is to implement our own Go context similar to the context provided, except that it doesn't carry the cancellation signal.

```go
type Context interface {
    Deadline() (deadline time.Time, ok bool)
    Done() <-chan struct{}
    Err() error
    Value(key any) any
}
```
The context's deadline is managed by the Deadline method and the Cancellation signal is managed via the Done and Err methods. 

```go
type detactContext struct {
	context.Context
}

func (d detactContext) Deadline() (time.Time, bool) {
	return time.Time{}, false
}

func (d detactContext) Done() <-chan struct{} {
	return nil
}

func (d detactContext) Err() error {
	return nil
}
```

Except for the Value method that calls the parent context to retrieve a value, the other methods return a default value so the context is never consider expired or canceled.

```go
err := publish(detach{ctx: r.Context()})
```

Now the context passed to publish will never expire or be canceled, but it will carry the parent context's values.

In summary, propagating a context should be done cautionsly. We illustrated that in this section with an example of handling an asynchronous action based on a context associated with an HTTP request. Because the context is canceled once we return the response, the asynchronous action also be stopped unexpectedly. Let's bear in mind the impacts of propagating a given context and, if necessary, that is always of propagation a given context and, if necessary, that it is always possible to create a custom context for a specific action.

## 62. Starting a goroutine without knowing when to stop it

Goroutines are easy and cheap to start, so easy and cheap that we may not necessarily have a plan for when to stop a new goroutine, which can lead to leaks. Not knowing when to stop a goroutine is a design issue and a common concurrency mistake in Go.

In terms of memory, a goroutine starts with a minimum stack size of 2 KB, which can grow and shrink as needed (the maximum stack size is 1 GB on 64-bit and 250 MB on 32-bit). Memory-wise, a goroutine can also hold variable references allocated to the heap. Meanwhile, a goroutine can hold resources such as HTTP or database connections, open files, and network sockets that should eventually be closed gracefully.

If goroutine is leaked, these kinds of resources will also be leaked.

Let's look at an example in which the point where a goroutine stops is unclear. Here, a parent goroutine calls a function that returns a channel and then creates a new goroutine that will keep receiving messages from this channel:

```go
ch := foo()
go func() {
    for v := range ch {
        // ...
    }
}()
```

The created goroutine will exit when ch is closed. But do we know exactly when this channel will be closed? It may not be evident, because ch is created by the foo function. If the channel is never closed, it's a leak. So, we should always be cautions about the exit points of a goroutine and make sure one is eventually reached.

```go
func main() {
    newWatcher()
}

type watcher struct {} 

func newWatcher() {
    w := watcher{}
    go w.Watch()
}
```

The problem with this code is that when the main goroutine exits (perhaps because of an OS signal or because it has a finite workload), the application is stopped. Hence, the resources created by watcher aren't closed gracefully.

